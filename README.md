# ğŸ”¬ ObservatÃ³rio da Comunidade CientÃ­fica (UA)

> **Uma abordagem de InteligÃªncia BibliomÃ©trica com Modelagem de TÃ³picos (NMF) e GenAI (Llama 3).**

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://observatoriocientifico.streamlit.app/) 
![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Status](https://img.shields.io/badge/Status-Completed-success)

## ğŸ“‹ Sobre o Projeto

Este projeto foi desenvolvido no Ã¢mbito do Mestrado em CiÃªncia de Dados para CiÃªncias Sociais da Universidade de Aveiro. O objetivo foi criar uma ferramenta capaz de analisar a estrutura, evoluÃ§Ã£o e distribuiÃ§Ã£o da produÃ§Ã£o cientÃ­fica da universidade, indo alÃ©m das mÃ©tricas tradicionais de contagem.

Utilizando dados da **Scopus (2020-2025)**, o sistema aplica tÃ©cnicas de **Processamento de Linguagem Natural (NLP)** para extrair tendÃªncias temÃ¡ticas latentes nos resumos dos artigos e apresenta os resultados num dashboard interativo desenvolvido em Streamlit.

### ğŸš€ Funcionalidades Principais

* **ğŸ“Š Painel de Desempenho:** MÃ©tricas de produtividade, citaÃ§Ãµes e Ã­ndice-h por departamento e autor.
* **ğŸ¤– Modelagem de TÃ³picos (Topic Modeling):** Uso do algoritmo **NMF (Non-negative Matrix Factorization)** para categorizar automaticamente milhares de *abstracts* em temas coerentes.
* **ğŸ§  Enriquecimento SemÃ¢ntico com LLM:** IntegraÃ§Ã£o inovadora com **Llama 3** para gerar rÃ³tulos legÃ­veis e descriÃ§Ãµes humanas para os tÃ³picos matemÃ¡ticos identificados.
* **ğŸ“ˆ TendÃªncias Temporais:** ClassificaÃ§Ã£o automÃ¡tica de tÃ³picos em "Consolidados" vs. "Emergentes".
* **ğŸŒ Redes de ColaboraÃ§Ã£o:** AnÃ¡lise geoespacial das parcerias internacionais da instituiÃ§Ã£o.

---

## ğŸ› ï¸ Tecnologias e Ferramentas

O projeto utiliza uma stack focada em Data Science e Web Dev em Python:

* **Linguagem:** Python 3
* **Dashboard:** [Streamlit](https://streamlit.io/)
* **VisualizaÃ§Ã£o:** Plotly Express & Plotly Graph Objects
* **NLP & ML:**
    * `scikit-learn` (NMF, TF-IDF)
    * `spaCy` (PrÃ©-processamento, NER, Lemmatization)
* **GenAI:** Llama 3 (via `ollama`) para rotulagem de tÃ³picos.
* **Dados:** Pandas, NumPy.

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```bash
â”œâ”€â”€ app.py                                # AplicaÃ§Ã£o principal (Dashboard Streamlit)
â”œâ”€â”€ AnaliseBibliometrica_E_Conteudo.ipynb # Notebook: IngestÃ£o, Limpeza, EDA e Modelo NMF
â”œâ”€â”€ Enriquecimento_ParaODashboard.ipynb   # Notebook: IntegraÃ§Ã£o com Llama 3 para rotulagem
â”œâ”€â”€ data/                                 # Pasta com os CSVs processados
â”œâ”€â”€ requirements.txt                      # DependÃªncias do projeto
â””â”€â”€ README.md                             # DocumentaÃ§Ã£o
```

---

âš™ï¸ Metodologia e Pipeline
O fluxo de dados segue trÃªs etapas principais detalhadas nos notebooks:

1. IngestÃ£o e Processamento
Coleta: ExtraÃ§Ã£o de metadados bibliogrÃ¡ficos da Scopus.

NLP: Pipeline com spaCy para tokenizaÃ§Ã£o, remoÃ§Ã£o de stopwords e filtragem gramatical (apenas substantivos e adjetivos para reduzir ruÃ­do).

VetorizaÃ§Ã£o: TF-IDF com n-grams para representaÃ§Ã£o numÃ©rica dos textos.

2. Modelagem e GenAI
NMF (Non-negative Matrix Factorization): FatorizaÃ§Ã£o da matriz TF-IDF em 10 tÃ³picos latentes. Este algoritmo foi escolhido pela sua interpretabilidade superior em textos curtos (abstracts) comparado ao LDA.

LLM Labeling: Os vetores de palavras de cada tÃ³pico foram enviados ao Llama 3, que retornou um nome curto e uma descriÃ§Ã£o para cada tema (ex: transformando uma lista de palavras como "solar, cells, energy" em "Energias RenovÃ¡veis").

3. VisualizaÃ§Ã£o
ConstruÃ§Ã£o da interface em Streamlit (app.py).

ImplementaÃ§Ã£o de filtros dinÃ¢micos que cruzam dados temporais com tÃ³picos semÃ¢nticos.

ğŸ–¥ï¸ Como Executar Localmente
Siga estes passos para rodar o dashboard na sua mÃ¡quina:

Clone o repositÃ³rio:

Bash

git clone [https://github.com/SEU_USUARIO/NOME_DO_REPO.git](https://github.com/Vitoria-analyst/Observatorio-da-Comunidade-Cientifica.git)
cd Observatorio-da-Comunidade-Cientifica
Instale as dependÃªncias:

Bash

pip install -r requirements.txt
Execute o Streamlit:

Bash

streamlit run app.py

---
ğŸ‘©â€ğŸ’» Autores
VitÃ³ria Rodrigues - [LinkedIn](https://www.linkedin.com/in/vitoria-rodrigues-/)
